{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa474ac-543f-4222-b72b-44e2d224e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class ProfessionalAIDataPipeline(AIDataPipeline):\n",
    "    \"\"\"\n",
    "    Pipeline ETL avanc√© : Extraction, Nettoyage, Ing√©nierie de Features \n",
    "    et Chargement pour l'entra√Ænement de mod√®les de recommandation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_base_url='http://localhost:8080/api'):\n",
    "        super().__init__(api_base_url)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def process_and_clean_data(self, data):\n",
    "        \"\"\"Phase de transformation (T de ETL) : Nettoyage et Enrichissement\"\"\"\n",
    "        print(\"üõ†Ô∏è  D√©but de la phase de transformation...\")\n",
    "        \n",
    "        # 1. Pr√©paration des interactions avec normalisation temporelle\n",
    "        df_interactions = self._prepare_weighted_interactions(data['interactions'])\n",
    "        \n",
    "        # 2. Nettoyage des recettes (d√©tection de doublons et compl√©tion de donn√©es)\n",
    "        df_recipes = self._clean_recipe_data(data['recipes'])\n",
    "        \n",
    "        # 3. Calcul du score de popularit√© hybride (Interaction + Note)\n",
    "        df_popularity = self._calculate_hybrid_popularity(df_interactions, data['ratings'])\n",
    "        \n",
    "        return {\n",
    "            'matrix': df_interactions,\n",
    "            'features': df_recipes,\n",
    "            'popularity': df_popularity\n",
    "        }\n",
    "\n",
    "    def _prepare_weighted_interactions(self, interactions):\n",
    "        \"\"\"Cr√©e une matrice d'interaction avec 'Decay Factor' (les interactions r√©centes p√®sent plus)\"\"\"\n",
    "        if not interactions: return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(interactions)\n",
    "        df['dateInteraction'] = pd.to_datetime(df['dateInteraction'])\n",
    "        \n",
    "        # Calcul du poids temporel (Time Decay)\n",
    "        # Plus l'interaction est ancienne, moins elle a d'impact sur l'IA\n",
    "        now = datetime.now(df['dateInteraction'].iloc[0].tzinfo)\n",
    "        df['days_ago'] = (now - df['dateInteraction']).dt.days\n",
    "        df['time_decay'] = np.exp(-0.05 * df['days_ago']) # D√©croissance exponentielle\n",
    "        \n",
    "        weight_map = {'CONSULTATION': 1, 'PARTAGE': 3, 'FAVORI_AJOUTE': 5}\n",
    "        df['base_weight'] = df['typeInteraction'].map(weight_map).fillna(1)\n",
    "        df['final_score'] = df['base_weight'] * df['time_decay']\n",
    "        \n",
    "        return df.pivot_table(index='userId', columns='recetteId', values='final_score', fill_value=0)\n",
    "\n",
    "    def _clean_recipe_data(self, recipes):\n",
    "        \"\"\"Normalisation des features de contenu pour le clustering/similarit√©\"\"\"\n",
    "        df = pd.DataFrame(recipes)\n",
    "        \n",
    "        # Remplissage des valeurs manquantes intelligemment\n",
    "        df['tempsPreparation'] = df['tempsPreparation'].fillna(df['tempsPreparation'].median())\n",
    "        df['difficulte'] = df['difficulte'].replace('', 'MOYEN').fillna('MOYEN')\n",
    "        \n",
    "        # Ing√©nierie de features : Ratio temps/difficult√©\n",
    "        diff_map = {'FACILE': 1, 'MOYEN': 2, 'DIFFICILE': 3}\n",
    "        df['diff_num'] = df['difficulte'].map(diff_map).fillna(2)\n",
    "        df['complexity_index'] = df['tempsPreparation'] * df['diff_num']\n",
    "        \n",
    "        # Normalisation des valeurs num√©riques entre 0 et 1 (Essentiel pour les mod√®les de Deep Learning)\n",
    "        cols_to_scale = ['tempsPreparation', 'complexity_index']\n",
    "        df[cols_to_scale] = self.scaler.fit_transform(df[cols_to_scale])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _calculate_hybrid_popularity(self, df_interactions, ratings):\n",
    "        \"\"\"Calcule un score de tendance (Trending Score)\"\"\"\n",
    "        # Somme des interactions par recette\n",
    "        pop_series = df_interactions.sum(axis=0)\n",
    "        \n",
    "        # Int√©gration des notes moyennes\n",
    "        if ratings:\n",
    "            df_ratings = pd.DataFrame(ratings)\n",
    "            avg_ratings = df_ratings.groupby('recetteId')['note'].mean()\n",
    "            # Score hybride = 70% interactions + 30% notes\n",
    "            popularity = (pop_series * 0.7) + (avg_ratings * 0.3)\n",
    "        else:\n",
    "            popularity = pop_series\n",
    "            \n",
    "        return popularity.sort_values(ascending=False)\n",
    "\n",
    "    def run_pipeline(self, output_path='ai_training_data'):\n",
    "        \"\"\"Ex√©cution compl√®te du flux de donn√©es\"\"\"\n",
    "        # Extraction\n",
    "        raw_data = self.collect_training_data()\n",
    "        \n",
    "        # Transformation\n",
    "        processed = self.process_and_clean_data(raw_data)\n",
    "        \n",
    "        # Chargement (Export)\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        processed['matrix'].to_csv(f\"{output_path}/interaction_matrix.csv\")\n",
    "        processed['features'].to_csv(f\"{output_path}/recipe_features_cleaned.csv\", index=False)\n",
    "        processed['popularity'].to_csv(f\"{output_path}/trending_scores.csv\")\n",
    "        \n",
    "        print(f\"\\nüöÄ Pipeline termin√©. {len(processed['features'])} recettes pr√™tes pour l'entra√Ænement.\")\n",
    "        return processed\n",
    "\n",
    "# Initialisation\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = ProfessionalAIDataPipeline()\n",
    "    # pipeline.login(...)\n",
    "    # results = pipeline.run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
