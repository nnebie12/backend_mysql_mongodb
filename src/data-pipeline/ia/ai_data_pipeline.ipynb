{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6065b42-6433-480d-b33f-0871da1f1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "\n",
    "class AIDataPipeline:\n",
    "    \n",
    "    def __init__(self, api_base_url='http://localhost:8080/api'):\n",
    "        self.api_base_url = api_base_url\n",
    "        self.token = None\n",
    "    \n",
    "    def login(self, email, password):\n",
    "        \"\"\"Authentification\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.api_base_url}/v1/auth/login\",\n",
    "            json={'email': email, 'motDePasse': password}\n",
    "        )\n",
    "        self.token = response.json()['token']\n",
    "        print(\"‚úÖ Authentifi√©\")\n",
    "    \n",
    "    def collect_training_data(self):\n",
    "        \"\"\"Collecte toutes les donn√©es n√©cessaires pour l'IA\"\"\"\n",
    "        headers = {'Authorization': f'Bearer {self.token}'}\n",
    "        \n",
    "        print(\"üìä Collecte des donn√©es d'entra√Ænement...\")\n",
    "        \n",
    "        # 1. R√©cup√©rer toutes les recettes\n",
    "        recipes = self._fetch_all_recipes(headers)\n",
    "        \n",
    "        # 2. R√©cup√©rer toutes les interactions\n",
    "        interactions = self._fetch_all_interactions(headers)\n",
    "        \n",
    "        # 3. R√©cup√©rer l'historique de recherche\n",
    "        searches = self._fetch_search_history(headers)\n",
    "        \n",
    "        # 4. R√©cup√©rer les notes et commentaires\n",
    "        ratings = self._fetch_ratings(headers)\n",
    "        \n",
    "        print(f\"‚úÖ Donn√©es collect√©es:\")\n",
    "        print(f\"  - Recettes: {len(recipes)}\")\n",
    "        print(f\"  - Interactions: {len(interactions)}\")\n",
    "        print(f\"  - Recherches: {len(searches)}\")\n",
    "        print(f\"  - Notes: {len(ratings)}\")\n",
    "        \n",
    "        return {\n",
    "            'recipes': recipes,\n",
    "            'interactions': interactions,\n",
    "            'searches': searches,\n",
    "            'ratings': ratings\n",
    "        }\n",
    "    \n",
    "    def _fetch_all_recipes(self, headers):\n",
    "        \"\"\"R√©cup√®re toutes les recettes\"\"\"\n",
    "        response = requests.get(\n",
    "            f\"{self.api_base_url}/v1/recettes/all\",\n",
    "            headers=headers\n",
    "        )\n",
    "        return response.json()\n",
    "    \n",
    "    def _fetch_all_interactions(self, headers):\n",
    "        \"\"\"R√©cup√®re toutes les interactions\"\"\"\n",
    "        # Selon votre API, adapter l'endpoint\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{self.api_base_url}/v1/recette-interactions/all\",\n",
    "                headers=headers\n",
    "            )\n",
    "            return response.json()\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def _fetch_search_history(self, headers):\n",
    "        \"\"\"R√©cup√®re l'historique de recherche\"\"\"\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{self.api_base_url}/v1/historique-recherche/all\",\n",
    "                headers=headers\n",
    "            )\n",
    "            return response.json()\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def _fetch_ratings(self, headers):\n",
    "        \"\"\"R√©cup√®re toutes les notes\"\"\"\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{self.api_base_url}/v1/notes/all\",\n",
    "                headers=headers\n",
    "            )\n",
    "            return response.json()\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def prepare_user_item_matrix(self, data):\n",
    "        \"\"\"Cr√©e la matrice utilisateur-recette pour le collaborative filtering\"\"\"\n",
    "        \n",
    "        # Cr√©er un DataFrame des interactions\n",
    "        interactions_data = []\n",
    "        \n",
    "        for interaction in data['interactions']:\n",
    "            interactions_data.append({\n",
    "                'user_id': interaction['userId'],\n",
    "                'recipe_id': interaction['recetteId'],\n",
    "                'interaction_type': interaction['typeInteraction'],\n",
    "                'timestamp': interaction['dateInteraction']\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(interactions_data)\n",
    "        \n",
    "        # Pond√©rer les types d'interaction\n",
    "        weight_map = {\n",
    "            'CONSULTATION': 1,\n",
    "            'FAVORI_AJOUTE': 3,\n",
    "            'PARTAGE': 2,\n",
    "            'RECHERCHE': 1\n",
    "        }\n",
    "        \n",
    "        df['weight'] = df['interaction_type'].map(weight_map)\n",
    "        \n",
    "        # Cr√©er la matrice\n",
    "        matrix = df.groupby(['user_id', 'recipe_id'])['weight'].sum().unstack(fill_value=0)\n",
    "        \n",
    "        print(f\"üìä Matrice cr√©√©e: {matrix.shape}\")\n",
    "        \n",
    "        return matrix\n",
    "    \n",
    "    def prepare_content_features(self, recipes):\n",
    "        \"\"\"Pr√©pare les features de contenu pour le content-based filtering\"\"\"\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        for recipe in recipes:\n",
    "            # Vectoriser les caract√©ristiques\n",
    "            feature = {\n",
    "                'recipe_id': recipe['id'],\n",
    "                'type_recette': recipe.get('typeRecette', 'plat'),\n",
    "                'difficulte': recipe.get('difficulte', 'MOYEN'),\n",
    "                'temps_total': recipe.get('tempsPreparation', 0) + recipe.get('tempsCuisson', 0),\n",
    "                'vegetarien': recipe.get('vegetarien', False),\n",
    "                'cuisine': recipe.get('cuisine', 'francaise'),\n",
    "                'tags': recipe.get('tags', [])\n",
    "            }\n",
    "            \n",
    "            features.append(feature)\n",
    "        \n",
    "        df = pd.DataFrame(features)\n",
    "        \n",
    "        # One-hot encoding pour les features cat√©gorielles\n",
    "        df_encoded = pd.get_dummies(df, columns=['type_recette', 'difficulte', 'cuisine'])\n",
    "        \n",
    "        print(f\"üìä Features de contenu: {df_encoded.shape}\")\n",
    "        \n",
    "        return df_encoded\n",
    "    \n",
    "    def export_for_ai_training(self, data, output_dir='ai_training_data'):\n",
    "        \"\"\"Export les donn√©es au format requis par votre mod√®le IA\"\"\"\n",
    "        import os\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. Matrice utilisateur-recette\n",
    "        matrix = self.prepare_user_item_matrix(data)\n",
    "        matrix.to_csv(f'{output_dir}/user_recipe_matrix.csv')\n",
    "        \n",
    "        # 2. Features de contenu\n",
    "        content_features = self.prepare_content_features(data['recipes'])\n",
    "        content_features.to_csv(f'{output_dir}/recipe_features.csv', index=False)\n",
    "        \n",
    "        # 3. Donn√©es brutes pour MongoDB\n",
    "        with open(f'{output_dir}/raw_data.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2, default=str)\n",
    "        \n",
    "        # 4. Statistiques utilisateurs\n",
    "        user_stats = self._compute_user_stats(data)\n",
    "        user_stats.to_csv(f'{output_dir}/user_statistics.csv', index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Donn√©es export√©es dans {output_dir}/\")\n",
    "        \n",
    "        return output_dir\n",
    "    \n",
    "    def _compute_user_stats(self, data):\n",
    "        \"\"\"Calcule les statistiques par utilisateur pour la segmentation RFM\"\"\"\n",
    "        \n",
    "        stats = []\n",
    "        \n",
    "        # Grouper par utilisateur\n",
    "        user_interactions = {}\n",
    "        for interaction in data['interactions']:\n",
    "            user_id = interaction['userId']\n",
    "            if user_id not in user_interactions:\n",
    "                user_interactions[user_id] = []\n",
    "            user_interactions[user_id].append(interaction)\n",
    "        \n",
    "        for user_id, interactions in user_interactions.items():\n",
    "            # Recency: jours depuis derni√®re interaction\n",
    "            dates = [datetime.fromisoformat(i['dateInteraction'].replace('Z', '+00:00')) \n",
    "                    for i in interactions]\n",
    "            recency = (datetime.now(dates[0].tzinfo) - max(dates)).days\n",
    "            \n",
    "            # Frequency: nombre d'interactions\n",
    "            frequency = len(interactions)\n",
    "            \n",
    "            # Monetary: valeur bas√©e sur les types d'interaction\n",
    "            monetary = sum([3 if i['typeInteraction'] == 'FAVORI_AJOUTE' \n",
    "                          else 2 if i['typeInteraction'] == 'PARTAGE' \n",
    "                          else 1 \n",
    "                          for i in interactions])\n",
    "            \n",
    "            stats.append({\n",
    "                'user_id': user_id,\n",
    "                'recency': recency,\n",
    "                'frequency': frequency,\n",
    "                'monetary': monetary,\n",
    "                'last_interaction': max(dates).isoformat()\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(stats)\n",
    "\n",
    "# Utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = AIDataPipeline()\n",
    "    pipeline.login('dianekassi@admin.com', 'Mydayana48')\n",
    "    \n",
    "    # Collecter les donn√©es\n",
    "    data = pipeline.collect_training_data()\n",
    "    \n",
    "    # Exporter pour l'IA\n",
    "    pipeline.export_for_ai_training(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
