{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e350063c-59da-4f78-84b9-8ddc05620a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "D√âMONSTRATION NLP - SENTENCE TRANSFORMERS\n",
      "================================================================================\n",
      "\n",
      "üì¶ Installation des d√©pendances...\n",
      "pip install sentence-transformers scikit-learn numpy pandas\n",
      "ü§ñ Chargement du mod√®le NLP: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà| 199/199 [00:00<00:00, 1044.25it/s, Materializing param=\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le charg√©\n",
      "\n",
      "================================================================================\n",
      "TEST 1: Similarit√© entre recettes\n",
      "================================================================================\n",
      "\n",
      "Similarit√© Carbonara ‚Üî Risotto: 0.47\n",
      "(Les deux sont italiennes et contiennent du parmesan)\n",
      "Similarit√© Carbonara ‚Üî Salade: 0.51\n",
      "(Moins similaires - cuisines et types diff√©rents)\n",
      "\n",
      "================================================================================\n",
      "TEST 2: Recherche s√©mantique\n",
      "================================================================================\n",
      "üîç Recherche s√©mantique: 'un plat italien avec du fromage'\n",
      "‚úÖ Trouv√© 3 r√©sultats\n",
      "\n",
      "Requ√™te: 'un plat italien avec du fromage'\n",
      "\n",
      "R√©sultats:\n",
      "  0.53 - Pasta Carbonara\n",
      "  0.41 - Salade C√©sar\n",
      "  0.37 - Risotto aux champignons\n",
      "\n",
      "================================================================================\n",
      "TEST 3: Analyse de sentiment\n",
      "================================================================================\n",
      "\n",
      "'D√©licieux! Mes enfants ont ador√© cette recette!'\n",
      "  ‚Üí Tr√®s positif (score: 1.0)\n",
      "\n",
      "'Un peu d√©√ßu, c'√©tait trop sal√©'\n",
      "  ‚Üí Tr√®s n√©gatif (score: -1.0)\n",
      "\n",
      "'Correct, rien d'exceptionnel'\n",
      "  ‚Üí Neutre (score: 0.0)\n",
      "\n",
      "================================================================================\n",
      "TEST 4: Extraction de mots-cl√©s\n",
      "================================================================================\n",
      "\n",
      "Mots-cl√©s pour 'Pasta Carbonara':\n",
      "  p√¢tes, ≈ìufs, pancetta, pasta, carbonara\n",
      "\n",
      "================================================================================\n",
      "TEST 5: Clustering\n",
      "================================================================================\n",
      "üî¨ Clustering de 15 recettes en 3 groupes\n",
      "‚úÖ Clustering termin√©\n",
      "\n",
      "Recettes regroup√©es en 3 clusters:\n",
      "  Cluster 0: 5 recettes\n",
      "  Cluster 1: 5 recettes\n",
      "  Cluster 2: 5 recettes\n",
      "\n",
      "================================================================================\n",
      "‚úÖ D√âMONSTRATION TERMIN√âE\n",
      "================================================================================\n",
      "\n",
      "Statistiques:\n",
      "  Mod√®le: paraphrase-multilingual-MiniLM-L12-v2\n",
      "  Dimension: 384\n",
      "  Embeddings en cache: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class AdvancedRecipeNLP:\n",
    "    \n",
    "    def __init__(self, model_name='paraphrase-multilingual-MiniLM-L12-v2'):\n",
    "        \"\"\"\n",
    "        Initialise le service NLP\n",
    "        \n",
    "        Args:\n",
    "            model_name: Nom du mod√®le sentence-transformers\n",
    "                       'paraphrase-multilingual-MiniLM-L12-v2' pour fran√ßais\n",
    "                       384 dimensions, rapide et efficace\n",
    "        \"\"\"\n",
    "        print(f\"ü§ñ Chargement du mod√®le NLP: {model_name}\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.embeddings_cache = {}\n",
    "        print(\"‚úÖ Mod√®le charg√©\")\n",
    "    \n",
    "    def generate_recipe_embedding(self, recipe: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        G√©n√®re un embedding vectoriel pour une recette\n",
    "        \n",
    "        Args:\n",
    "            recipe: Dictionnaire contenant les donn√©es de la recette\n",
    "        \n",
    "        Returns:\n",
    "            Vecteur numpy de 384 dimensions\n",
    "        \"\"\"\n",
    "        recipe_id = recipe.get('id')\n",
    "        \n",
    "        # V√©rifier cache\n",
    "        if recipe_id in self.embeddings_cache:\n",
    "            return self.embeddings_cache[recipe_id]\n",
    "        \n",
    "        # Construire le texte\n",
    "        text_parts = []\n",
    "        \n",
    "        # Titre (poids important)\n",
    "        if recipe.get('titre'):\n",
    "            text_parts.append(recipe['titre'])\n",
    "            text_parts.append(recipe['titre'])  # Dupliquer pour donner plus de poids\n",
    "        \n",
    "        # Description\n",
    "        if recipe.get('description'):\n",
    "            text_parts.append(recipe['description'])\n",
    "        \n",
    "        # Type et cuisine\n",
    "        if recipe.get('typeRecette'):\n",
    "            text_parts.append(f\"Type: {recipe['typeRecette']}\")\n",
    "        \n",
    "        if recipe.get('cuisine'):\n",
    "            text_parts.append(f\"Cuisine: {recipe['cuisine']}\")\n",
    "        \n",
    "        # Ingr√©dients\n",
    "        if recipe.get('ingredients'):\n",
    "            ingredients_text = \"Ingr√©dients: \" + \", \".join([\n",
    "                ing['nom'] if isinstance(ing, dict) else str(ing)\n",
    "                for ing in recipe['ingredients']\n",
    "            ])\n",
    "            text_parts.append(ingredients_text)\n",
    "        \n",
    "        # Caract√©ristiques\n",
    "        if recipe.get('vegetarien'):\n",
    "            text_parts.append(\"v√©g√©tarien\")\n",
    "        \n",
    "        if recipe.get('difficulte'):\n",
    "            text_parts.append(f\"Difficult√©: {recipe['difficulte']}\")\n",
    "        \n",
    "        # Combiner tout\n",
    "        full_text = \". \".join(text_parts)\n",
    "        \n",
    "        # G√©n√©rer l'embedding avec sentence-transformers\n",
    "        embedding = self.model.encode(full_text, convert_to_numpy=True)\n",
    "        \n",
    "        # Mettre en cache\n",
    "        if recipe_id:\n",
    "            self.embeddings_cache[recipe_id] = embedding\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    def calculate_similarity(self, recipe1: Dict, recipe2: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Calcule la similarit√© cosinus entre deux recettes\n",
    "        \n",
    "        Returns:\n",
    "            Score de similarit√© entre 0 et 1\n",
    "        \"\"\"\n",
    "        emb1 = self.generate_recipe_embedding(recipe1)\n",
    "        emb2 = self.generate_recipe_embedding(recipe2)\n",
    "        \n",
    "        # Reshape pour sklearn\n",
    "        emb1 = emb1.reshape(1, -1)\n",
    "        emb2 = emb2.reshape(1, -1)\n",
    "        \n",
    "        similarity = cosine_similarity(emb1, emb2)[0][0]\n",
    "        \n",
    "        return float(similarity)\n",
    "    \n",
    "    def find_similar_recipes(\n",
    "        self, \n",
    "        target_recipe: Dict, \n",
    "        candidate_recipes: List[Dict], \n",
    "        top_k: int = 10\n",
    "    ) -> List[Tuple[Dict, float]]:\n",
    "        \"\"\"\n",
    "        Trouve les K recettes les plus similaires\n",
    "        \n",
    "        Returns:\n",
    "            Liste de tuples (recette, score_similarit√©)\n",
    "        \"\"\"\n",
    "        target_emb = self.generate_recipe_embedding(target_recipe)\n",
    "        \n",
    "        similarities = []\n",
    "        \n",
    "        for candidate in candidate_recipes:\n",
    "            # Ne pas comparer avec elle-m√™me\n",
    "            if candidate.get('id') == target_recipe.get('id'):\n",
    "                continue\n",
    "            \n",
    "            candidate_emb = self.generate_recipe_embedding(candidate)\n",
    "            \n",
    "            # Calculer similarit√©\n",
    "            target_emb_reshaped = target_emb.reshape(1, -1)\n",
    "            candidate_emb_reshaped = candidate_emb.reshape(1, -1)\n",
    "            similarity = cosine_similarity(target_emb_reshaped, candidate_emb_reshaped)[0][0]\n",
    "            \n",
    "            similarities.append((candidate, float(similarity)))\n",
    "        \n",
    "        # Trier par similarit√© d√©croissante\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return similarities[:top_k]\n",
    "    \n",
    "    def semantic_search(\n",
    "        self, \n",
    "        query: str, \n",
    "        recipes: List[Dict], \n",
    "        top_k: int = 10\n",
    "    ) -> List[Tuple[Dict, float]]:\n",
    "        \"\"\"\n",
    "        Recherche s√©mantique: trouve des recettes pertinentes pour une requ√™te\n",
    "        \n",
    "        Args:\n",
    "            query: Requ√™te en langage naturel\n",
    "                   Ex: \"quelque chose de l√©ger et frais pour l'√©t√©\"\n",
    "        \n",
    "        Returns:\n",
    "            Liste de tuples (recette, score_pertinence)\n",
    "        \"\"\"\n",
    "        print(f\"üîç Recherche s√©mantique: '{query}'\")\n",
    "        \n",
    "        # G√©n√©rer embedding de la requ√™te\n",
    "        query_emb = self.model.encode(query, convert_to_numpy=True)\n",
    "        \n",
    "        scores = []\n",
    "        \n",
    "        for recipe in recipes:\n",
    "            recipe_emb = self.generate_recipe_embedding(recipe)\n",
    "            \n",
    "            # Calculer similarit√©\n",
    "            query_emb_reshaped = query_emb.reshape(1, -1)\n",
    "            recipe_emb_reshaped = recipe_emb.reshape(1, -1)\n",
    "            score = cosine_similarity(query_emb_reshaped, recipe_emb_reshaped)[0][0]\n",
    "            \n",
    "            scores.append((recipe, float(score)))\n",
    "        \n",
    "        # Trier par pertinence\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"‚úÖ Trouv√© {len(scores)} r√©sultats\")\n",
    "        \n",
    "        return scores[:top_k]\n",
    "    \n",
    "    def analyze_sentiment(self, text: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyse de sentiment simple bas√©e sur des mots-cl√©s\n",
    "        Pour une vraie analyse, utiliser un mod√®le sp√©cialis√©\n",
    "        \n",
    "        Returns:\n",
    "            {\"score\": float, \"label\": str}\n",
    "        \"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Mots positifs fran√ßais\n",
    "        positive_words = [\n",
    "            'd√©licieux', 'excellent', 'parfait', 'super', 'g√©nial', 'ador√©',\n",
    "            'magnifique', 'succulent', 'savoureux', 'top', 'bravo', 'merci',\n",
    "            'r√©ussi', 'facile', 'rapide', 'bon', 'tr√®s bon', 'recommande'\n",
    "        ]\n",
    "        \n",
    "        # Mots n√©gatifs fran√ßais\n",
    "        negative_words = [\n",
    "            'mauvais', 'horrible', 'rat√©', 'd√©√ßu', 'd√©cevant', 'nul',\n",
    "            'fade', 'sec', 'dur', 'trop', 'pas bon', 'bof', 'moyen',\n",
    "            'difficile', 'compliqu√©', '√©chec'\n",
    "        ]\n",
    "        \n",
    "        # Compter les occurrences\n",
    "        positive_count = sum(1 for word in positive_words if word in text_lower)\n",
    "        negative_count = sum(1 for word in negative_words if word in text_lower)\n",
    "        \n",
    "        # Calculer le score\n",
    "        total = positive_count + negative_count\n",
    "        \n",
    "        if total == 0:\n",
    "            score = 0.0\n",
    "            label = \"Neutre\"\n",
    "        else:\n",
    "            score = (positive_count - negative_count) / total\n",
    "            \n",
    "            if score > 0.5:\n",
    "                label = \"Tr√®s positif\"\n",
    "            elif score > 0.2:\n",
    "                label = \"Positif\"\n",
    "            elif score > -0.2:\n",
    "                label = \"Neutre\"\n",
    "            elif score > -0.5:\n",
    "                label = \"N√©gatif\"\n",
    "            else:\n",
    "                label = \"Tr√®s n√©gatif\"\n",
    "        \n",
    "        return {\n",
    "            \"score\": round(score, 2),\n",
    "            \"label\": label,\n",
    "            \"positive_words_found\": positive_count,\n",
    "            \"negative_words_found\": negative_count\n",
    "        }\n",
    "    \n",
    "    def extract_keywords(self, recipe: Dict, top_n: int = 10) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extrait les mots-cl√©s importants d'une recette\n",
    "        Utilise TF-IDF simplifi√©\n",
    "        \"\"\"\n",
    "        # Construire le texte\n",
    "        text_parts = []\n",
    "        \n",
    "        if recipe.get('titre'):\n",
    "            text_parts.append(recipe['titre'])\n",
    "        \n",
    "        if recipe.get('description'):\n",
    "            text_parts.append(recipe['description'])\n",
    "        \n",
    "        if recipe.get('ingredients'):\n",
    "            for ing in recipe['ingredients']:\n",
    "                if isinstance(ing, dict):\n",
    "                    text_parts.append(ing.get('nom', ''))\n",
    "                else:\n",
    "                    text_parts.append(str(ing))\n",
    "        \n",
    "        full_text = \" \".join(text_parts).lower()\n",
    "        \n",
    "        # Nettoyer\n",
    "        full_text = re.sub(r'[^\\w\\s]', ' ', full_text)\n",
    "        \n",
    "        # Mots √† ignorer (stop words fran√ßais simplifi√©s)\n",
    "        stop_words = {\n",
    "            'le', 'la', 'les', 'un', 'une', 'des', 'de', 'du', 'et', 'ou',\n",
    "            '√†', 'au', 'aux', 'en', 'pour', 'avec', 'sans', 'dans', 'sur',\n",
    "            'cette', 'ces', 'ce', 'son', 'sa', 'ses', 'notre', 'nos', 'votre',\n",
    "            'vos', 'leur', 'leurs', 'qui', 'que', 'dont', 'o√π'\n",
    "        }\n",
    "        \n",
    "        # Extraire les mots\n",
    "        words = full_text.split()\n",
    "        words = [w for w in words if len(w) > 3 and w not in stop_words]\n",
    "        \n",
    "        # Compter les fr√©quences\n",
    "        word_counts = Counter(words)\n",
    "        \n",
    "        # Retourner les plus fr√©quents\n",
    "        keywords = [word for word, count in word_counts.most_common(top_n)]\n",
    "        \n",
    "        return keywords\n",
    "    \n",
    "    def cluster_recipes(self, recipes: List[Dict], n_clusters: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Regroupe les recettes en clusters bas√©s sur leur similarit√©\n",
    "        Utilise K-means sur les embeddings\n",
    "        \"\"\"\n",
    "        from sklearn.cluster import KMeans\n",
    "        \n",
    "        print(f\"üî¨ Clustering de {len(recipes)} recettes en {n_clusters} groupes\")\n",
    "        \n",
    "        # G√©n√©rer tous les embeddings\n",
    "        embeddings = []\n",
    "        recipe_ids = []\n",
    "        \n",
    "        for recipe in recipes:\n",
    "            emb = self.generate_recipe_embedding(recipe)\n",
    "            embeddings.append(emb)\n",
    "            recipe_ids.append(recipe.get('id'))\n",
    "        \n",
    "        embeddings_array = np.array(embeddings)\n",
    "        \n",
    "        # K-means clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(embeddings_array)\n",
    "        \n",
    "        # Organiser par cluster\n",
    "        clusters = {i: [] for i in range(n_clusters)}\n",
    "        \n",
    "        for idx, recipe in enumerate(recipes):\n",
    "            cluster_id = int(cluster_labels[idx])\n",
    "            clusters[cluster_id].append({\n",
    "                'id': recipe.get('id'),\n",
    "                'titre': recipe.get('titre'),\n",
    "                'type': recipe.get('typeRecette')\n",
    "            })\n",
    "        \n",
    "        print(\"‚úÖ Clustering termin√©\")\n",
    "        \n",
    "        return {\n",
    "            'n_clusters': n_clusters,\n",
    "            'clusters': clusters,\n",
    "            'cluster_sizes': {i: len(clusters[i]) for i in range(n_clusters)}\n",
    "        }\n",
    "    \n",
    "    def generate_recipe_matrix(self, recipes: List[Dict]) -> Tuple[np.ndarray, List]:\n",
    "        \"\"\"\n",
    "        G√©n√®re la matrice compl√®te d'embeddings pour toutes les recettes\n",
    "        Utile pour l'analyse globale\n",
    "        \n",
    "        Returns:\n",
    "            (matrice_embeddings, liste_ids)\n",
    "        \"\"\"\n",
    "        print(f\"üìä G√©n√©ration matrice pour {len(recipes)} recettes\")\n",
    "        \n",
    "        embeddings = []\n",
    "        recipe_ids = []\n",
    "        \n",
    "        for recipe in recipes:\n",
    "            emb = self.generate_recipe_embedding(recipe)\n",
    "            embeddings.append(emb)\n",
    "            recipe_ids.append(recipe.get('id'))\n",
    "        \n",
    "        matrix = np.array(embeddings)\n",
    "        \n",
    "        print(f\"‚úÖ Matrice g√©n√©r√©e: {matrix.shape}\")\n",
    "        \n",
    "        return matrix, recipe_ids\n",
    "    \n",
    "    def save_embeddings(self, filepath: str = 'recipe_embeddings.npz'):\n",
    "        \"\"\"\n",
    "        Sauvegarde les embeddings en cache\n",
    "        \"\"\"\n",
    "        if not self.embeddings_cache:\n",
    "            print(\"‚ö†Ô∏è Aucun embedding en cache\")\n",
    "            return\n",
    "        \n",
    "        # Convertir en arrays\n",
    "        ids = list(self.embeddings_cache.keys())\n",
    "        embeddings = np.array(list(self.embeddings_cache.values()))\n",
    "        \n",
    "        # Sauvegarder\n",
    "        np.savez_compressed(filepath, ids=ids, embeddings=embeddings)\n",
    "        \n",
    "        print(f\"üíæ {len(ids)} embeddings sauvegard√©s dans {filepath}\")\n",
    "    \n",
    "    def load_embeddings(self, filepath: str = 'recipe_embeddings.npz'):\n",
    "        \"\"\"\n",
    "        Charge les embeddings depuis un fichier\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = np.load(filepath, allow_pickle=True)\n",
    "            ids = data['ids']\n",
    "            embeddings = data['embeddings']\n",
    "            \n",
    "            # Reconstruire le cache\n",
    "            self.embeddings_cache = {\n",
    "                int(id_): emb for id_, emb in zip(ids, embeddings)\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ {len(ids)} embeddings charg√©s depuis {filepath}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ö†Ô∏è Fichier {filepath} non trouv√©\")\n",
    "    \n",
    "    def get_cache_stats(self) -> Dict:\n",
    "    # On essaie de r√©cup√©rer le nom du mod√®le, sinon on met une valeur par d√©faut\n",
    "        model_name = getattr(self.model, \"model_name_or_path\", \"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "    \n",
    "        return {\n",
    "            'total_embeddings': len(self.embeddings_cache),\n",
    "            'model_name': model_name,\n",
    "            'embedding_dimension': self.model.get_sentence_embedding_dimension()\n",
    "        }\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"D√âMONSTRATION NLP - SENTENCE TRANSFORMERS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Installer les d√©pendances\n",
    "    print(\"\\nüì¶ Installation des d√©pendances...\")\n",
    "    print(\"pip install sentence-transformers scikit-learn numpy pandas\")\n",
    "    \n",
    "    # Initialiser le service\n",
    "    nlp = AdvancedRecipeNLP()\n",
    "    \n",
    "    # Exemple de recettes\n",
    "    recipes = [\n",
    "        {\n",
    "            'id': 1,\n",
    "            'titre': 'Pasta Carbonara',\n",
    "            'description': 'Plat italien traditionnel avec des p√¢tes, ≈ìufs et pancetta',\n",
    "            'typeRecette': 'plat',\n",
    "            'cuisine': 'italienne',\n",
    "            'ingredients': ['p√¢tes', '≈ìufs', 'pancetta', 'parmesan'],\n",
    "            'vegetarien': False,\n",
    "            'difficulte': 'MOYEN'\n",
    "        },\n",
    "        {\n",
    "            'id': 2,\n",
    "            'titre': 'Salade C√©sar',\n",
    "            'description': 'Salade fra√Æche avec laitue, poulet grill√© et cro√ªtons',\n",
    "            'typeRecette': 'entree',\n",
    "            'cuisine': 'americaine',\n",
    "            'ingredients': ['laitue', 'poulet', 'cro√ªtons', 'parmesan'],\n",
    "            'vegetarien': False,\n",
    "            'difficulte': 'FACILE'\n",
    "        },\n",
    "        {\n",
    "            'id': 3,\n",
    "            'titre': 'Risotto aux champignons',\n",
    "            'description': 'Risotto cr√©meux aux champignons de saison',\n",
    "            'typeRecette': 'plat',\n",
    "            'cuisine': 'italienne',\n",
    "            'ingredients': ['riz arborio', 'champignons', 'parmesan', 'bouillon'],\n",
    "            'vegetarien': True,\n",
    "            'difficulte': 'MOYEN'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 1: Similarit√© entre recettes\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    similarity = nlp.calculate_similarity(recipes[0], recipes[2])\n",
    "    print(f\"\\nSimilarit√© Carbonara ‚Üî Risotto: {similarity:.2f}\")\n",
    "    print(\"(Les deux sont italiennes et contiennent du parmesan)\")\n",
    "    \n",
    "    similarity = nlp.calculate_similarity(recipes[0], recipes[1])\n",
    "    print(f\"Similarit√© Carbonara ‚Üî Salade: {similarity:.2f}\")\n",
    "    print(\"(Moins similaires - cuisines et types diff√©rents)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 2: Recherche s√©mantique\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    query = \"un plat italien avec du fromage\"\n",
    "    results = nlp.semantic_search(query, recipes, top_k=3)\n",
    "    \n",
    "    print(f\"\\nRequ√™te: '{query}'\")\n",
    "    print(\"\\nR√©sultats:\")\n",
    "    for recipe, score in results:\n",
    "        print(f\"  {score:.2f} - {recipe['titre']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 3: Analyse de sentiment\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    comments = [\n",
    "        \"D√©licieux! Mes enfants ont ador√© cette recette!\",\n",
    "        \"Un peu d√©√ßu, c'√©tait trop sal√©\",\n",
    "        \"Correct, rien d'exceptionnel\"\n",
    "    ]\n",
    "    \n",
    "    for comment in comments:\n",
    "        sentiment = nlp.analyze_sentiment(comment)\n",
    "        print(f\"\\n'{comment}'\")\n",
    "        print(f\"  ‚Üí {sentiment['label']} (score: {sentiment['score']})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 4: Extraction de mots-cl√©s\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    keywords = nlp.extract_keywords(recipes[0], top_n=5)\n",
    "    print(f\"\\nMots-cl√©s pour '{recipes[0]['titre']}':\")\n",
    "    print(f\"  {', '.join(keywords)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEST 5: Clustering\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Ajouter plus de recettes pour le clustering\n",
    "    all_recipes = recipes * 5  # Simuler plus de recettes\n",
    "    \n",
    "    clusters = nlp.cluster_recipes(all_recipes, n_clusters=3)\n",
    "    \n",
    "    print(f\"\\nRecettes regroup√©es en {clusters['n_clusters']} clusters:\")\n",
    "    for cluster_id, size in clusters['cluster_sizes'].items():\n",
    "        print(f\"  Cluster {cluster_id}: {size} recettes\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ D√âMONSTRATION TERMIN√âE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Statistiques\n",
    "    stats = nlp.get_cache_stats()\n",
    "    print(f\"\\nStatistiques:\")\n",
    "    print(f\"  Mod√®le: {stats['model_name']}\")\n",
    "    print(f\"  Dimension: {stats['embedding_dimension']}\")\n",
    "    print(f\"  Embeddings en cache: {stats['total_embeddings']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a2c0a-83d2-4bd5-b08b-c34af3bb973b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
