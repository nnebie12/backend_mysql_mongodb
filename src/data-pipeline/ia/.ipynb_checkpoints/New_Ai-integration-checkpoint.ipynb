{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "519d4cf0-c425-42d7-a835-2f838579a0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ TESTS DE CHARGE (Recommendation Engine)\n",
      "------------------------------------------------------------\n",
      "‚ùå Stress Test /recommendations/trends: L'API n'a pas r√©pondu correctement.\n",
      "\n",
      "üîç VALIDATION S√âMANTIQUE (NLP Engine)\n",
      "------------------------------------------------------------\n",
      "‚úÖ NLP Semantic Search: Trouv√© 10 recettes pour 'un plat l√©ger pour l'√©t√©'\n",
      "\n",
      "üìä INT√âGRIT√â DES DONN√âES\n",
      "------------------------------------------------------------\n",
      "‚úÖ CSV Sync Check: Donn√©e synchronis√©e: P√¢te √† pizza fine\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class AIIntegrationTester:\n",
    "    def __init__(self, api_base_url):\n",
    "        self.api_base_url = api_base_url\n",
    "        self.test_results = []\n",
    "\n",
    "    def _log_success(self, test_name, message):\n",
    "        print(f\"‚úÖ {test_name}: {message}\")\n",
    "        self.test_results.append({'test': test_name, 'status': 'SUCCESS', 'message': message})\n",
    "\n",
    "    def _log_failure(self, test_name, message):\n",
    "        print(f\"‚ùå {test_name}: {message}\")\n",
    "        self.test_results.append({'test': test_name, 'status': 'FAILURE', 'message': message})\n",
    "\n",
    "    def _log_warning(self, test_name, message):\n",
    "        print(f\"‚ö†Ô∏è {test_name}: {message}\")\n",
    "        self.test_results.append({'test': test_name, 'status': 'WARNING', 'message': message})\n",
    "\n",
    "    def run_all_tests(self):\n",
    "        # Cette m√©thode sera compl√©t√©e ou surcharg√©e\n",
    "        pass\n",
    "\n",
    "    def generate_test_report(self):\n",
    "        print(\"\\n--- G√©n√©ration du rapport de test ---\")\n",
    "\n",
    "class AdvancedAIValidator(AIIntegrationTester):\n",
    "    \"\"\"\n",
    "    Validateur IA de niveau production : inclut tests de charge, \n",
    "    validation de contenu NLP et int√©grit√© des donn√©es.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_base_url='http://localhost:8080/api/v1'):\n",
    "        super().__init__(api_base_url)\n",
    "\n",
    "    def run_production_suite(self):\n",
    "        print(\"\\nüöÄ TESTS DE CHARGE (Recommendation Engine)\")\n",
    "        print(\"-\" * 60)\n",
    "        # Test sur l'endpoint Trends de votre RecommendationController\n",
    "        self.test_stress_concurrency(endpoint=\"/recommendations/trends\", threads=5)\n",
    "        \n",
    "        print(\"\\nüîç VALIDATION S√âMANTIQUE (NLP Engine)\")\n",
    "        print(\"-\" * 60)\n",
    "        # Test sur votre NLPController\n",
    "        self.test_nlp_semantic_search(\"un plat l√©ger pour l'√©t√©\")\n",
    "        \n",
    "        print(\"\\nüìä INT√âGRIT√â DES DONN√âES\")\n",
    "        print(\"-\" * 60)\n",
    "        # On utilise le CSV g√©n√©r√© pr√©c√©demment au lieu d'un JSON\n",
    "        self.validate_csv_data(\"recettes_clean.csv\")\n",
    "\n",
    "    def test_stress_concurrency(self, endpoint, threads=5):\n",
    "        test_name = f\"Stress Test {endpoint}\"\n",
    "        url = f\"{self.api_base_url}{endpoint}\"\n",
    "        \n",
    "        def call_api():\n",
    "            start = time.time()\n",
    "            try:\n",
    "                resp = requests.get(url, timeout=15)\n",
    "                return (resp.status_code == 200, (time.time() - start) * 1000)\n",
    "            except:\n",
    "                return (False, 0)\n",
    "\n",
    "        results = []\n",
    "        with ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "            results = list(executor.map(lambda _: call_api(), range(threads * 2)))\n",
    "\n",
    "        successes = [r[1] for r in results if r[0]]\n",
    "        if successes:\n",
    "            avg_lat = np.mean(successes)\n",
    "            self._log_success(test_name, f\"OK. Latence moyenne: {avg_lat:.0f}ms\")\n",
    "        else:\n",
    "            self._log_failure(test_name, \"L'API n'a pas r√©pondu correctement.\")\n",
    "\n",
    "    def validate_data_indexing(self, filename):\n",
    "        \"\"\"V√©rifie que les donn√©es locales sont bien synchronis√©es avec le moteur IA\"\"\"\n",
    "        test_name = \"Data Sync Validation\"\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                local_data = json.load(f)\n",
    "            \n",
    "            # On prend la derni√®re recette du fichier pour v√©rifier si elle existe en API\n",
    "            last_recipe_name = local_data[-1][1] \n",
    "            \n",
    "            response = requests.get(f\"{self.api_base_url}/v1/recettes/search\", params={'name': last_recipe_name})\n",
    "            \n",
    "            if response.status_code == 200 and len(response.json()) > 0:\n",
    "                self._log_success(test_name, f\"Indexation confirm√©e pour : {last_recipe_name}\")\n",
    "            else:\n",
    "                self._log_warning(test_name, f\"Recette '{last_recipe_name}' non trouv√©e. Pipeline de donn√©es possiblement en retard.\")\n",
    "        except Exception as e:\n",
    "            self._log_failure(test_name, f\"Erreur fichier : {str(e)}\")\n",
    "\n",
    "    def test_nlp_semantic_search(self, query):\n",
    "        test_name = \"NLP Semantic Search\"\n",
    "        url = f\"{self.api_base_url}/nlp/search/semantic\"\n",
    "        try:\n",
    "            # Votre contr√¥leur attend une Map avec la cl√© \"query\"\n",
    "            payload = {\"query\": query}\n",
    "            resp = requests.post(url, json=payload, timeout=10)\n",
    "            if resp.status_code == 200:\n",
    "                count = resp.json().get('total_results', 0)\n",
    "                self._log_success(test_name, f\"Trouv√© {count} recettes pour '{query}'\")\n",
    "            else:\n",
    "                self._log_failure(test_name, f\"Code erreur: {resp.status_code}\")\n",
    "        except Exception as e:\n",
    "            self._log_failure(test_name, str(e))\n",
    "\n",
    "    def validate_csv_data(self, filename):\n",
    "        test_name = \"CSV Sync Check\"\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            # On prend un titre au hasard dans le CSV pour v√©rifier s'il existe en base via l'API\n",
    "            sample_title = df['titre'].iloc[0]\n",
    "            url = f\"{self.api_base_url}/nlp/search/semantic\"\n",
    "            resp = requests.post(url, json={\"query\": sample_title})\n",
    "            \n",
    "            if resp.status_code == 200 and resp.json().get('total_results', 0) > 0:\n",
    "                self._log_success(test_name, f\"Donn√©e synchronis√©e: {sample_title}\")\n",
    "            else:\n",
    "                self._log_warning(test_name, \"Donn√©e CSV non trouv√©e par l'IA.\")\n",
    "        except Exception as e:\n",
    "            self._log_failure(test_name, f\"Fichier {filename} introuvable.\")\n",
    "            \n",
    "\n",
    "    def generate_enhanced_report(self):\n",
    "        \"\"\"G√©n√®re un rapport visuel et statistique\"\"\"\n",
    "        super().generate_test_report()\n",
    "        df = pd.DataFrame(self.test_results)\n",
    "        \n",
    "        # Petit r√©sum√© console plus propre\n",
    "        print(\"\\nüìù R√âSUM√â ANALYTIQUE\")\n",
    "        print(df.groupby('status').size().to_string())\n",
    "        \n",
    "        # Export CSV pour archivage historique (audit)\n",
    "        df.to_csv(f\"audit_ia_{datetime.now().strftime('%Y%m%d')}.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tester = AdvancedAIValidator()\n",
    "    tester.run_production_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced20fe9-1189-47eb-8141-b58a2da47183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
